{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "organized-oxygen",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Jina Workshop @ EuroPython: Building a Neural Image Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-makeup",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "In this workshop we will build a neural search engine for images of Pokemons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbcfb36-6c1a-4fc2-a397-d28a0b5e2b89",
   "metadata": {},
   "source": [
    "# TABLE OF CONTENTS\n",
    "\n",
    "...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-compression",
   "metadata": {},
   "source": [
    "# Downloading data and model\n",
    "\n",
    "Skip this if you've already downloaded them.\n",
    "\n",
    "## Download and Extract Data\n",
    "\n",
    "For this example we're using Pokemon sprites from [veekun.com](https://veekun.com/dex/downloads). To download them run:\n",
    "\n",
    "```sh\n",
    "sh ./get_data.sh\n",
    "```\n",
    "\n",
    "## Download and Extract Pretrained Model\n",
    "\n",
    "In this example we use [BiT (Big Transfer) model](https://github.com/google-research/big_transfer), To download it:\n",
    "\n",
    "```sh\n",
    "sh ./download.sh\n",
    "```"
   ]
  },
  {
   "attachments": {
    "07a57670-02d0-4b37-89d4-e40fa91fe617.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoAgMAAADxkFD+AAAADFBMVEX///+l1oQZEBBKpVrbdx+K\nAAABKUlEQVQY05XQMUsCYQDG8f+9cXBYOGYY2BUNfYYmv8TpEHjSEk6uhcFdRmCbi+HoUsRrdAUa\nbecYTS7tRyCEoS4N5sG9DXfW3DP9pmf4w78n/mgMfmk+LLV/Xk6UvhQJVzq7uYRGOn+Q0GzqteOY\nT/nidza+D1/9yaYLpOphUJ3kAmD7UJ7VJusBYFasVtjLtAET62j6tdUGDCrOYmi3AVO7nkV9pwHU\n9aI386IXoNEqbX6G4QZw0ypdqejuFMSOVairWT8AYVnWWHm+C8ZUdl3fk4DISklVfQB72luB0mIO\nGEip2SoChFbmwhkpF+jPtZPw0XaB9L1V8JrFDoAxsqNBJgAwcn6Uj7mmj+UwptCd954dADBSz55y\n43rdecqPyWogomV+l1v4AZcxc6uK8D1EAAAAAElFTkSuQmCC\n"
    },
    "4fdcaf41-1adb-4eef-9770-94a112369dfe.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAADAAAAAwAgMAAAAqbBEUAAAADFBMVEX///+l1oQZEBBKpVrbdx+K\nAAABc0lEQVQokWNgoA54dQDBZrr6AsGxDn2E4Chdb2iAcxr2NxjA2MwMegwKcP0MXAwcMA4PkMsO\n43AwMDaIwTgmDIwFcI4CA2tCHIyjwhCaCOfohtbX1sM43KGvfv6Acbi2r9q9A2qlUtOiVfsWQG3p\nUF60atcGqMGSXS9WvTq1Asxp23tyl/aaRUpgzgq9q/9WbQotA/uogWNt3aqV88PBnmBq6P7Htnr3\nV7AnOBKYXrCv3r3XCWxaxKoV8qtW708DcRSrGWPjVijtvgHiqE5hCL+1gEF7O4jDF8q49fcbBqZt\nIA7n1NDQf3EHgCEE0lN6NfT/9EdruEEczbCQ9v/zf/8CO+dFeND7/6v/hoOd0xUapf23bovoA1DY\ndjQo6T+MfxIO4nCJhrrGN8Q/jQdx9FhDQ6sb4nf9B3FWNa1avk60/v06oAFM1av2n/o1ff3rFQlA\njuKr//9X6Um3rQQp6+tbtYrvVdW8JlhEMm9e85qBaAAAlDCFn/mqVXMAAAAASUVORK5CYII=\n"
    },
    "dd9fe45f-6be4-4822-ae92-2d281b56c0ff.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAADgAAAA4AgMAAADV6NONAAAADFBMVEX///+l1oQZEBBKpVrbdx+K\nAAACpklEQVQYGQXBQWhbdRzA8e/7h7I0kfYU9LTGYaBLYT15TtzRUxz9J7GFpHhwI8PhTaho/tbD\n3PAQoXGjXrJCIPk9zdulMFN8Cd6FXdYNPTQOh90rJvMQDS/b++/zAQBiLqBaAMBSt3qfwA0NCSDW\nQs+WdN2OSBq4uEEqegcthmRAbK9A6kuDsw3KdhIdSNUNThkYRL7sOcXP7fBFBVizQ+d5sdwfDF9U\nAGWhePfuj+tQNcBgyPTa/d+2ceoG+O5l7NW3n/1rSNWAWIFYFHv57mEgBlAFnP9uvlEXrgGwx7T8\n93KQzykDKM20mDn+hRzbwKL+Qte6f/wPvAUsXp3W7kTuCXAeUIPjrp5HD5ed904MMAga1XrUyA0L\nVw0oe4v6SbiXG26cjUCFaXKPg/YyqfkMkqMGy+eCdp43oxkkd/OwIO0CO74PSuUhddT9MD9avQQs\nFqB44/lmaUQcWPwU51j+LA4MAOvPOPf7ykHRMwCsd/XWk+rTYs8AcEma3qmMvhcAkLl4t1da/f0O\nQMIZhN431dbR/scGSHdLkX9Bnro/NGtAJ1Wf+KvnD37SlaZBqTvR/EF6pV96pHdaqHtbnrRWa97E\nf6W3iScqSZFea+CH48cdEs0d1dab5ro/Hz8rE9dHxtl89MGN+cT/J+DtrZ/NgtZa3F5/XOTilo/W\nWldE+uMnZPY7zidaH1YDkfGIhIjWGxldD0VkBGsfNXXhlr4eiTww4F7I6Ctf6WCW7Z2CYjejy7dL\nYXB5EEH2ysOmLietneizCL7u6R3PTqy1YRTBTdvLypq1Ezu3h4Y190Ck40YDO63+lUZJKHYmrvUa\npXkasiPPRpEXSaMUGkjsuta69ky1S6cA6n0RGxDPVn8FoLWgA4in13cBWBIB1L3aKgAAQMLAa79M\nR9jveT6JAAAAAElFTkSuQmCC\n"
    }
   },
   "cell_type": "markdown",
   "id": "steady-singapore",
   "metadata": {},
   "source": [
    "# The problem\n",
    "\n",
    "We want to search Pokemon by pictures! For example \n",
    "\n",
    "![1.png](attachment:07a57670-02d0-4b37-89d4-e40fa91fe617.png)\n",
    "\n",
    "May return\n",
    "\n",
    "![2.png](attachment:4fdcaf41-1adb-4eef-9770-94a112369dfe.png) ![3.png](attachment:dd9fe45f-6be4-4822-ae92-2d281b56c0ff.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-badge",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-heading",
   "metadata": {},
   "source": [
    "Required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d3c463-54a0-4a4d-9f7f-c80315a5ad49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0a1e19-f923-446f-be1b-8e21e67b88b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from shutil import rmtree\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "\n",
    "from jina import Flow, DocumentArray, Document\n",
    "\n",
    "from jinahub.image.normalizer import ImageNormalizer\n",
    "from jinahub.image.encoder.big_transfer import BigTransferEncoder\n",
    "from jinahub.image.encoder.torch_encoder import ImageTorchEncoder\n",
    "\n",
    "from components import MemMapIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banned-policy",
   "metadata": {},
   "source": [
    "Some configuration options.\n",
    "\n",
    "- restrict the nr of docs we index\n",
    "- the path to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-letters",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO adapt nr of image. pre-index dataset before workshop\n",
    "num_docs = int(os.environ.get('JINA_MAX_DOCS', 5))\n",
    "image_src = 'data/**/*.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-outside",
   "metadata": {},
   "source": [
    "Environment variables\n",
    "\n",
    "- workspace (folder where the encoded data will be stored)\n",
    "- port we will listen on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = './workspace'\n",
    "os.environ['JINA_WORKSPACE'] = workspace\n",
    "os.environ['JINA_PORT'] = os.environ.get('JINA_PORT', str(45678))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-ceramic",
   "metadata": {},
   "source": [
    "We need to make sure to not index on top of an existing workspace. \n",
    "\n",
    "This can cause problems if you are using different configuration options between the two runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-sight",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(workspace):\n",
    "    print(f'Workspace at {workspace} exists. Will delete')\n",
    "    rmtree(workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-conspiracy",
   "metadata": {},
   "source": [
    "# Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasonable-sullivan",
   "metadata": {},
   "source": [
    "The Flow is the main pipeline in Jina. It describes the way data should be loaded, processed, stored etc. within the system. \n",
    "\n",
    "It is made up of components (called Executors), which are the ones doing the specific task.\n",
    "\n",
    "Ex. we have a crafter Executor, which preprocesses the data; an Encoder Executor, which loads the model and *encodes* that data;  Indexer Executor, which stores and retrieves the data etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-thomson",
   "metadata": {},
   "source": [
    "## Index\n",
    "\n",
    "This is the Flow we use to perform operations on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Flow.load_config('flows/flow.yml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578e6b0e-26ac-41bb-8223-c788ac74676a",
   "metadata": {},
   "source": [
    "We can plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-giant",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.plot('index.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-details",
   "metadata": {},
   "source": [
    "The Flow is a context manager (like a file handler). Within the context, it starts all the Executors within their processes / threads.\n",
    "\n",
    "We load data into the pipeline from the directory we provided above. \n",
    "\n",
    "`request_size` dictates how many images should be sent in one request (~batching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfc880-acb9-4b58-9ca7-1995ae61913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs(image_src, num_docs):\n",
    "    docs = DocumentArray()\n",
    "\n",
    "    for file in glob(image_src, recursive=True):\n",
    "        # Uniform Resource Identifier\n",
    "        doc = Document(uri=file)\n",
    "        doc.convert_image_uri_to_blob()\n",
    "        doc.tags['filename'] = file\n",
    "        docs.append(doc)\n",
    "        if len(docs) == num_docs:\n",
    "            break\n",
    "            \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e07c3-ff42-4211-9670-17ae230ef060",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs = get_docs(image_src, num_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ca4748-fda2-4e49-be5f-a517bc3e33b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with f:\n",
    "    f.post(\n",
    "        on='/index',\n",
    "        inputs=docs,\n",
    "        request_size=64,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da2fb59-f0e3-4d7f-9593-2e204830c586",
   "metadata": {},
   "source": [
    "# Questions?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-moderator",
   "metadata": {},
   "source": [
    "## Searching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be61c13a-1593-49fc-95c7-7ca6dee606ec",
   "metadata": {},
   "source": [
    "We load the first image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a1b30-b8ba-4635-bf84-44d5c93092fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_image = list(glob(image_src, recursive=True))[0]\n",
    "\n",
    "# Let's plot the image\n",
    "\n",
    "pil_im = Image.open(search_image)\n",
    "imshow(pil_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61831869-c4a3-43f8-a24b-97a40221700b",
   "metadata": {},
   "source": [
    "We build a Document with that image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f068941-159d-470e-a7ef-82d80dc42a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_docs = get_docs(image_src, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807c080-0798-47b0-bdd8-8bb6e7084050",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_docs[0].tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-reliance",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with f:\n",
    "    return_docs = f.post(\n",
    "        on='/search',\n",
    "        inputs=query_docs,\n",
    "        parameters={'top_k': 5},\n",
    "        return_results=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbd61ee-ec07-4e37-a434-d00f4ef1c15e",
   "metadata": {},
   "source": [
    "Retrieving tags (image path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2190a0-153f-40ed-b8c8-0f13f7143dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top match is the same image\n",
    "assert return_docs[0].docs[0].matches[0].tags['filename'] == return_docs[0].docs[0].tags['filename']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e156b9b-4a67-4a11-bd13-88c4bac34928",
   "metadata": {},
   "source": [
    "Reconstructing the original image from the Document content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6b1ff-0fb3-4385-9e5c-12f790a3b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in return_docs[0].docs[0].matches:\n",
    "    content = match.content*255\n",
    "    img_array = content.astype(np.uint8)\n",
    "    img = Image.fromarray(img_array)\n",
    "    imshow(img)\n",
    "    plt.title(match.tags['filename'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virtual-think",
   "metadata": {},
   "source": [
    "# Questions?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848fd1d2-f13a-4683-a044-17e5795ba316",
   "metadata": {},
   "source": [
    "# Advanced Topics\n",
    "\n",
    "\n",
    "**NOTE**: After configuring these, you will need to re-index your data and search again. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45c02a2-382d-499f-a183-923039a4e9c8",
   "metadata": {},
   "source": [
    "## 1. Changing Encoders\n",
    "\n",
    "We can switch the `Encoder` easily.\n",
    "\n",
    "This is the component that is the actual **model**. This encodes the images into a vector space upon which you can perform cosine similarity (or other linear algebra operations).\n",
    "\n",
    "\n",
    "`flows/flow.yml`:\n",
    "\n",
    "```yaml\n",
    "...\n",
    "  - name: encoder\n",
    "    timeout_ready: 600000\n",
    "    uses:\n",
    "        jtype: ImageTorchEncoder\n",
    "        with:\n",
    "          on_gpu: true\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4c2aae-7341-4a2d-bc2c-c949c4e28311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinahub.image.encoder.torch_encoder import ImageTorchEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd3646-cdbb-448c-a4c2-07c98d1b2945",
   "metadata": {},
   "source": [
    "Now we re-run the cells above with the new Flow. Make sure to **delete the workspace**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbbdeb3-d77e-4efc-a222-bbb2531de02f",
   "metadata": {},
   "source": [
    "# Questions?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9f4771-956f-463a-9666-9a1120abe180",
   "metadata": {},
   "source": [
    "## 2. Your own custom Executor\n",
    "\n",
    "Next let's delve one level deeper into Jina.\n",
    "\n",
    "So far we have looked at the Flow (top level) and the Document (one element of data).\n",
    "\n",
    "The intermediate level is the Executor (which is a component in the pipeline of the Flow).\n",
    "\n",
    "Let's create an Executor which \"logs\" the query results.\n",
    "\n",
    "OPTIONAL It's parallel.\n",
    "\n",
    "OPTIONAL It's hanging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-imagination",
   "metadata": {},
   "source": [
    "# Questions?\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {
    "1a98c688-569b-4b08-aa1d-3dbb7fadd38f.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoAgMAAADxkFD+AAAADFBMVEX///+l1oQZEBBKpVrbdx+K\nAAABDElEQVQY02NgIBkwIZgcB+BMhQ0wllVzApTF18kEZTIvUJGDMjn4HKKhTIUJrNUVEOY2h9Cf\nUhDjf5+anyvdAGRxNf1+oPtW7AFIpdKqBmkoUzO0oXqL+AwQkyE0Me+LPIjJwZBZ/+tCPFiUcen7\nf0vrO4DMJtbw9b9X/zsBZHZMjZP+/+u3BJC5bGrctP//1tQA7VKaWtf0//1WoLlMofH//+9fvR9k\n8atVq1b9X70K5BourRWz//9/AXbY1NDU179+gJjcq1ZNzf//D8TUTWBMif/3HqStsYK1aX5nNpDJ\n9PRXaFP8gmggk6Nj0SrWugWhIFElBqbsfY1i0HBo0mjigIaoRoPGAtIiAQDjzWNRFer//AAAAABJ\nRU5ErkJggg==\n"
    },
    "cb8f8cf6-92f7-4b7f-9a75-43029261979b.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAACgAAAAoAgMAAADxkFD+AAAADFBMVEX///+l1oQZEBBKpVrbdx+K\nAAABKUlEQVQY05XQMUsCYQDG8f+9cXBYOGYY2BUNfYYmv8TpEHjSEk6uhcFdRmCbi+HoUsRrdAUa\nbecYTS7tRyCEoS4N5sG9DXfW3DP9pmf4w78n/mgMfmk+LLV/Xk6UvhQJVzq7uYRGOn+Q0GzqteOY\nT/nidza+D1/9yaYLpOphUJ3kAmD7UJ7VJusBYFasVtjLtAET62j6tdUGDCrOYmi3AVO7nkV9pwHU\n9aI386IXoNEqbX6G4QZw0ypdqejuFMSOVairWT8AYVnWWHm+C8ZUdl3fk4DISklVfQB72luB0mIO\nGEip2SoChFbmwhkpF+jPtZPw0XaB9L1V8JrFDoAxsqNBJgAwcn6Uj7mmj+UwptCd954dADBSz55y\n43rdecqPyWogomV+l1v4AZcxc6uK8D1EAAAAAElFTkSuQmCC\n"
    }
   },
   "cell_type": "markdown",
   "id": "supported-martin",
   "metadata": {},
   "source": [
    "## 3. Optimization\n",
    "\n",
    "In every Flow that is build with Jina, there are quite some parameters to set.\n",
    "For example, if you use a pre-trained model for encoding, there is no obvious best choice for a given dataset.\n",
    "Jina allows you to try out a lot of different parameters automatically in order to get the best results.\n",
    "\n",
    "Therefor, you need to provide Jina some sort of evaluation metric.\n",
    "In the pokemon dataset, there are two edition with the same pokemon, but different images: `red-blue` and `red-green`.\n",
    "\n",
    "![1.png](attachment:cb8f8cf6-92f7-4b7f-9a75-43029261979b.png)![1.png](attachment:1a98c688-569b-4b08-aa1d-3dbb7fadd38f.png)\n",
    "\n",
    "Thus, we will setup the following evaluation metric:\n",
    "Index one edition and search with the other edition.\n",
    "We have a success, if the right pokemon is at the first place in the search results.\n",
    "\n",
    "We need to do the following steps:\n",
    "\n",
    "- A) build an `index` and a `search` Flow, which are repeaditly runnable\n",
    "- B) use the `red-blue` dataset for `index` and the `red-green` for `search`\n",
    "- C) implement an `EvaluationCallback` which will calculate, if the right pokemon is in the first place\n",
    "- D) set the needed `OptimizationParameter` via a `parameter.yml` file\n",
    "- E) setup the optimization process itself\n",
    "\n",
    "**NOTE**: Under the hood, we use [optuna](https://optuna.readthedocs.io/en/stable/) for hyperparameter optimization.\n",
    "\n",
    "### Do the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from jina import Document\n",
    "from jina.optimizers.flow_runner import SingleFlowRunner, MultiFlowRunner\n",
    "from jina.optimizers import FlowOptimizer, EvaluationCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-fossil",
   "metadata": {},
   "source": [
    "### A) & B)\n",
    "\n",
    "Jina provides the \n",
    "- `SingleFlowRunner` for making a Flow repeaditly runnable and the \n",
    "- `MultiFlowRunner` to chain multiple `SingleFlowRunner` for the `FlowOptimizer`\n",
    "\n",
    "For setup you need:\n",
    "- `flow_yaml`: the definition of a Flow\n",
    "- `documents`: the Documents, which are send to the Flow in each optimization step\n",
    "- `execution_method`: tell the Flow, whether `index` or `search` should be used\n",
    "\n",
    "Beware, that we introduce `JINA_MODEL_NAME_VAR: ${{JINA_MODEL_NAME}}` in the two new Flow definition.\n",
    "This variable will allow us to change the model in the Flow in each optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_iterator(edition, full_document):\n",
    "    image_src = f'data/pokemon/main-sprites/{edition}/*.png'\n",
    "    for filename in glob.iglob(image_src, recursive=True):\n",
    "        doc = Document(uri=filename)\n",
    "        doc.convert_image_uri_to_blob()\n",
    "\n",
    "        doc.blob = doc.blob.astype(np.uint8)\n",
    "        doc.tags['filename'] = filename\n",
    "        yield doc\n",
    "\n",
    "def get_flows():\n",
    "    index_flow = SingleFlowRunner(\n",
    "        flow_yaml='flows/flow_opt.yml',\n",
    "        documents=get_input_iterator('red-blue', True),\n",
    "        request_size=64,\n",
    "        execution_endpoint='/index',\n",
    "        overwrite_workspace=True\n",
    "    )\n",
    "\n",
    "    search_flow = SingleFlowRunner(\n",
    "        flow_yaml='flows/flow_opt.yml',\n",
    "        documents=get_input_iterator('red-green', False),\n",
    "        request_size=64,\n",
    "        execution_endpoint='/search'\n",
    "    )\n",
    "\n",
    "    multi_flow = MultiFlowRunner([index_flow, search_flow])\n",
    "    return multi_flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "global-database",
   "metadata": {},
   "source": [
    "### C) implement an `EvaluationCallback` which will calculate, if the right pokemon is in the first place\n",
    "\n",
    "Since the files are named the same for both editions, we use the filename as an identifier, whether we found the right pokemon.\n",
    "The `PokemonCallback` checks for each Document, whether the correct result is in the first position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id(filename):\n",
    "    return filename.split('/')[-1].split('.')[0]\n",
    "\n",
    "class PokemonCallback(EvaluationCallback):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._eval_name = \"pokedex_eval\"\n",
    "\n",
    "    def get_empty_copy(self):\n",
    "        return PokemonCallback(self._eval_name)\n",
    "    \n",
    "    def __call__(self, response):\n",
    "        self._n_docs += len(response.data.docs)\n",
    "        for doc in response.data.docs:\n",
    "            if doc.matches:\n",
    "                document_id = get_id(str(doc.tags.fields['filename']))\n",
    "                first_match_id = get_id(str(doc.matches[0].tags.fields['filename']))\n",
    "                if document_id == first_match_id:\n",
    "                    self._evaluation_values[self._eval_name].append(1)\n",
    "                else:\n",
    "                    self._evaluation_values[self._eval_name].append(0)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-dispatch",
   "metadata": {},
   "source": [
    "### D) set the needed `OptimizationParameter` via a `parameter.yml` file\n",
    "\n",
    "We defined in the `parameter_few.yml` the models, that the optimizer should try out.\n",
    "For demonstation purpose, we just added three models, in order to make the optimizer run rather short.\n",
    "If you want to try mode models, please use the `parameter.yml` file and increase `n_trials` parameter in the `FlowOptimizer` below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "christian-brooklyn",
   "metadata": {},
   "source": [
    "### E) setup the optimization process itself\n",
    "\n",
    "Finally, we build the `FlowOptimizer` object.\n",
    "It needs:\n",
    "- `flow_runner`: the repeaditly runnable Flow object\n",
    "- `parameter_yaml`: the parameters which the optimizer can change\n",
    "- `evaluation_callback`: our previously defined evaluation function\n",
    "- `workspace_base_dir`: A directory for temporary data\n",
    "- `n_trials`: The amount of optimization steps, that should be performed\n",
    "- `sampler`: the way, the `FlowOptimizer` should sample new values in each step. For more info please look at the [optuna docs](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.RandomSampler.html#optuna.samplers.RandomSampler)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-looking",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def optimize(flows):\n",
    "    optimizer = FlowOptimizer(\n",
    "        flow_runner=flows,\n",
    "        parameter_yaml='optimize/parameters_few.yml',\n",
    "        evaluation_callback=PokemonCallback(eval_name='correct'),\n",
    "        workspace_base_dir='workspace',\n",
    "        n_trials=3,\n",
    "        sampler='RandomSampler'\n",
    "    )\n",
    "    result = optimizer.optimize_flow()\n",
    "    result.save_parameters('optimize/best_config.yml')\n",
    "\n",
    "flows = get_flows()\n",
    "optimize(flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-student",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poked",
   "language": "python",
   "name": "poked"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
